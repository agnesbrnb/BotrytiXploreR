---
title: "Projet AnaStat"
output: html_document
---

## Chargement des données et construction des jeux d'apprentissage et de test

Les données représentent 184 femmes qui ont été touché par le cancer du sein ainsi que leur taux d'expression pour 4654 gènes. Nous disposons également d'une variable "label" indiquant la rechute ou non pour chaque femme. L'objectif ici est de déterminer la meilleure méthode d'apprentissage statistique pour prédire la rechute du cancer du sein. Tout d'abord les données sont chargées, mises en forme et divisées en 2 jeux de données : un d'apprentissage et un de test. 
Nous avons donc 184 observations pour 4654 covariables et une variable à expliquer. Nous avons donc beaucoup plus de paramètres que d'observations ce qui complique la construction d'un bon modèle. 

```{r}
set.seed(2018)
setwd("/Volumes/LACIE SHARE/Disque_Agnes/Fac/M2/Ana-Stat")
train <- t(read.table("xtrain.txt", sep="\t", as.is = NA))

data = numeric()
for (i in 2:nrow(train)){
  data <- rbind(data, as.numeric(train[i,]))
}
data <- cbind(data, read.table("ytrain.txt"))
colnames(data) <- c(train[1,], "label")

data <- within(data, {
  label = factor(label, labels = c("-1","1"))
})

test <- sample(1:nrow(data),round(nrow(data)/3))
train <- (1:nrow(data))[-test]
train <- data[train,]
test <- data[test,]

cat("Dimension des données :",dim(data), "\n")
str(data)
table(data$label)
```

## Régression logistique multiple

La méthode de régression logistique multiple vise à sélectionner les paramètres en testant l'influence de chaque covariable sur le modèle. Si l'absence de la covariable réduit la qualité du modèle alors sa présence est importante. Ainsi, le meilleur modèle est sélectionné. 
```{r}
data.glm <- glm(label~., data=data, family = binomial)
summary(data.glm)
```

On observe que l'algorithme ne converge pas sur les données surement du au fait du grand nombre de covariables (4654) par rapport au nombre d'observations (184). En effet, la méthode glm ne permet d'estimer que n-1 paramètres où n est le nombre d'observations. Ce modèle ne correspond donc pas aux données. 

## Arbre CART

La méthode CART vise à construire un arbre de décision à partir des covariables. A chaque noeud construit est associé une condition dépendant des covariables. On construit l'arbre maximal à partir des données d'apprentissage puis on réalise une étape d'élagage pour réduire le nombre de feuilles. Cependant, on observe que l'arbre maximal possède 17 feuilles ce qui est peu. On utilise les informations sur l'élagage optimale obtenues avec la fonction rpart pour effectuer l'élagage de l'arbre maximal. On obtient alors un arbre à 7 feuilles.
```{r}
set.seed(2018)
library(rpart)
t.max = rpart(label~., data=train, control=rpart.control(cp = 0))
t.prune = prune(t.max, cp = t.max$cptable[which.min(t.max$cptable[,4]), 1])

cat("Arbre maximal\n")
print(t.max)
plot(t.max)
text(t.max, cex=1)

cat("\nArbre après élagage\n")
print(t.prune)
plot(t.prune)
text(t.prune, cex=1)
```

On calcule l'erreur de classification sur l'arbre après élagage donc le taux de mal classés à partir du jeu de test.
```{r}
set.seed(2018)
pred_t = predict(t.prune, newdata = test, type="class")
cat("Erreur de classifaction :",sum(test$label != pred_t)/length(test$label))
```

Estimation de l'erreur de classification par validation croisée
```{r}
set.seed(2018)
ind_fold = sample(1:5, nrow(data), replace=TRUE)
cv.cart = numeric()

# Chaque sous ensemble prend le role de jeu test à son tour
for(i in 1:5){
  fit.cart = rpart(label~., data=data[ind_fold!=i,])
  proba.cart = predict(fit.cart, newdata=data[ind_fold==i,], type="class") 
  
  y.test = data[ind_fold==i,"label"] # valeur test observée
  cv.cart = c(cv.cart, mean(y.test != proba.cart))
}

cat("Erreur de classifaction par validation croisée :",mean(cv.cart))
```


## Forêt aléatoire

(Décrire randomforest) On réalise la méthode de classification random forest pour expliquer les données y par les covariables. On observe ici un taux d'erreur très important. En effet l'OOB, estimation du taux de mal classés sur l'ensemble des données, est de 39,02% et l'erreur de classification calculée est de 36%. Cette méthode a une erreur plus faible que l'arbre CART mais si elle reste élevée. Ce résultat était attendu puisque la méthode randomForest est efficace dans le traitement de modèle avec un grand nombre de paramètres.

```{r}
set.seed(2018)
library(glmnet)
library(randomForest)

data.rf = randomForest(label~., data=train)
data.rf

pred.rf <- predict(data.rf, newdata=test)
cat("Erreur de classifaction :",mean(test$label != pred.rf))
```

On calcule l'erreur de classification par validation croisée.
```{r}
set.seed(2018)
ind_fold = sample(1:5, nrow(data), replace=TRUE)
cv.rf = numeric()

# Chaque sous ensemble prend le role de jeu test à son tour
for(i in 1:5){
  fit.rf = randomForest(label~., data=data[ind_fold!=i,])
  proba.rf = predict(fit.rf, newdata=data[ind_fold==i,], type="class") 
  
  y.test = data[ind_fold==i,"label"] # valeur test observée
  cv.rf = c(cv.rf, mean(y.test != proba.rf))
}

cat("Erreur de classifaction par validation croisée :",mean(cv.rf))
```

## Méthode de bagging

Il s'agit d'une méthode similaire au random forest mais on utilise toutes les covariables pour la construction de chaque noeud et pas un échantillon. (à vérifier)
```{r}
set.seed(2018)
fit.bag <- randomForest(label~., data = data, mtry=ncol(data)-1)
fit.bag
```


## Méthode LASSO

(décrire LASSO)
```{r}
set.seed(2018)
X <- model.matrix(label~., train)[,-(ncol(data))]
Y <- train$label

Xt <- model.matrix(label~., test)[,-(ncol(data))]
Yt <- test$label


fit.lasso <- glmnet(X,Y,family = "binomial")

cv.out = cv.glmnet(X, Y,family = "binomial",lambda = seq(exp(-4),1,length = 500))
plot(cv.out)
```

```{r}
set.seed(2018)
(best <- cv.out$lambda.min)

res.lasso <- glmnet(X,Y,family = "binomial",lambda = seq(exp(-4),1,length = 500))
proba.lasso <- predict(res.lasso, s=best, newx = Xt,type = "response")
pred.lasso <- rep("1",length(proba.lasso))
pred.lasso[which(proba.lasso > 0.5)] = "-1"

cat("Erreur de classifaction par validation croisée :",sum(as.character(Yt) == pred.lasso)/length(pred.lasso))
```

## Méthode SVM

(Décrire SVM)
```{r}
library(e1071)

tune.out = tune(svm, label~., data = train, kernel = "radial",
                ranges = list(
                  cost = c(1,100,1000),
                  gamma = c(0.1,1,3)
                ))
summary(tune.out)

fit.svm = svm(label~., train, kernel="radial", probability=TRUE, cost=tune.out$best.parameters$cost, gamma=tune.out$best.parameters$gamma)

cat("Erreur de classifaction par validation croisée :",mean(test$label != predict(fit.svm,newdata = test)))

```

On peut tracer la courbe ROC afin de visualiser l'erreur d'apprentissage

